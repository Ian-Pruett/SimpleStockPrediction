import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
import tensorflow as tf
# from tensorflow.keras import Sequential
# from tensorflow.keras.layers import Dense, Dropout
# from tensorflow.keras.layers import LSTM, TimeDistributed

import tensorflow.keras as keras


# define base directory
base_dir = ''

'''
    Tensorflow fun facts:
    input_dim = X.shape[1]
    inputs = Input(shape=(input_dim,))
    
    ALSO CHECK THIS OUT:
    model.summary()

    plot_model(model, to_file='output.png')
'''

# look_back is the number of times steps to look back
# where as look_ahead is the number of times steps
# to predict
def process_dataset1(frame, look_back=1, look_ahead=1):
    D = frame.values.astype('float32')
    
    # scale data between 0,1
    scaler = MinMaxScaler(feature_range=(0,1))
    D = scaler.fit_transform(D)
    
    X,y = [],[]
    
    i = 0
    n = len(D)-look_back-1

    for i in range(0,n,look_ahead):
        j = i + look_back
        k = j + look_ahead
        X_entry = D[i:j,0]
        y_entry = D[j:k,0]
        X.append(X_entry)
        y.append(y_entry)

    return np.array(X),np.array(y)

def load_dataframe(stock):
    # read file into dataframe
    filepath = base_dir + 'data/processed/'+ stock + '.open.txt'
    dataframe = pd.read_csv(
        filepath,
        usecols=[1], 
        engine='python',
        skipfooter=3
    )
    return dataframe


def process_dataset(frame, look_back=1):
    D = frame.values.astype('float32')
    
    # scale data between 0,1
    scaler = MinMaxScaler(feature_range=(0,1))
    D = scaler.fit_transform(D)
    
    X,y = [],[]
    
    for i in range(len(D)-look_back-1):
        entry = D[i:(i+look_back), 0]
        X.append(entry)
        y.append(D[i + look_back, 0])
    
    return np.array(X),np.array(y)


def simple_lstm_network():
    model = keras.Sequential()

    # first layer
    model.add(keras.layers.LSTM(
        units=30,
        activation='tanh',
        recurrent_activation='sigmoid',
        recurrent_dropout=0,
        unroll=False,
        use_bias=True,
    ))
    
    model.add(keras.layers.Dropout(0.2))

    # output layer
    model.add(keras.layers.Dense(1))
    

    model.compile(
        loss='mse',
        optimizer='adam',
        metrics=['accuracy','mae']
    )

    return model


def main():
    dataframe = load_dataframe('aapl')

    X,y = process_dataset1(dataframe,look_back=30,look_ahead=1)

    X = np.expand_dims(X,axis=2)
    # y = np.expand_dims(y,axis=1)

    X_train,X_test,y_train,y_test = train_test_split(
        X,y,
        test_size=.33
    )

    model = simple_lstm_network()

    model.fit(
        X_train,y_train,
        batch_size=10,
        epochs=5
    )

    predictions = model.predict([X_test])

    loss, acc, mae = model.evaluate(X_test,y_test)
    print('Loss: %f\tAcc: %f\tMAE: %f' % (loss,acc,mae))

    plt.plot(y_test)
    plt.plot(predictions)
    plt.show()
   

if __name__ == '__main__':
    main()